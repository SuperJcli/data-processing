import numpy as np
import pandas as pd

SAR_data = 'D:/SAR_retrieval'

##数据读取
def loaddata(data_path):
    csv_path = os.path.join(data_path,'data.csv')
    return pd.read_csv(csv_path)

polarSAR = loaddata(SAR_data)

#数据可视化，分析得到数据的分布
polarSAR.hist(bins = 50,figsize = (20,15))
plt.show()

colnm = polarSAR.columns.tolist()
fig = plt.figure(figsize=(20, 20))
 
for i in range(12):
    plt.subplot(4, 3, i + 1)
    sns.boxplot(polarSAR[colnm[i]], orient="v", width=0.2)
    plt.ylabel(colnm[i], fontsize=20)
# plt.subplots_adjust(left=0.2, wspace=0.8, top=0.9)
 
plt.tight_layout()

##数据集划分
def test_set_check(identifier,test_ratio):
    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio

def split_train_test_by_id(data,test_ratio,id_column,hash=hashlib.md5):
    ids = data[id_column]
    in_test_set = ids.apply(lambda id_:test_set_check(id_,test_ratio,hash))
    return data.loc[~in_test_set],data.loc[in_test_set]

polarSAR_with_id = polarSAR.reset_index() # adds an 'index' column
train_set,test_set = split_train_test_by_id(polarSAR,0.2,"index")

#数据集划分的另外一种方式
###################################################################################
from sklearn.model_selection import train_test_split
train_set ,test_set = train_test_split(data, test_size = 0.2,random_state=42) 
#data:your datasets,test_size:ratio of testsets,random_state:随机种子数
####################################################################################
